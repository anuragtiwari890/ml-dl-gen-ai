{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation: One-Hot Encoding and Word Embeddings\n",
    "\n",
    "### This Jupyter Notebook demonstrates two fundamental techniques for converting text data into numerical representations that can be used as input for machine learning models, particularly neural networks: One-Hot Encoding and Word Embeddings.\n",
    "\n",
    "## Key Concepts Covered:\n",
    "\n",
    "1.  **Text Data Preparation**: Defining a list of example sentences to illustrate the process.\n",
    "2.  **Vocabulary Size Definition**: Establishing a `voc_size` (vocabulary size) which determines the range for unique word representations.\n",
    "3.  **One-Hot Encoding (`one_hot`)**:\n",
    "    * Converting each word in a sentence into a unique integer representation based on a predefined vocabulary size.\n",
    "    * This process results in a list of integer sequences, where each integer corresponds to a specific word.\n",
    "4.  **Padding Sequences (`pad_sequences`)**:\n",
    "    * Ensuring all integer sequences (sentences) have a uniform length, which is a requirement for neural network inputs.\n",
    "    * Padding (adding zeros) is applied to shorter sequences to match the `maxlen` (maximum sentence length).\n",
    "5.  **Word Embedding Representation (`Embedding` layer)**:\n",
    "    * Introducing TensorFlow/Keras's `Embedding` layer, which learns dense vector representations (embeddings) for words.\n",
    "    * Unlike one-hot encoding, word embeddings capture semantic relationships between words, representing them in a lower-dimensional continuous vector space.\n",
    "6.  **Building a Simple Embedding Model**:\n",
    "    * Creating a `Sequential` Keras model containing only an `Embedding` layer.\n",
    "    * Configuring the `Embedding` layer with `voc_size` (input dimension), `dim` (output dimension/embedding size), and `input_length` (padded sequence length).\n",
    "    * Compiling the model with a dummy optimizer and loss for demonstration purposes, as the primary goal here is to observe the embedding output.\n",
    "7.  **Generating Embeddings**: Using the model's `predict` method to obtain the learned word embeddings for the padded input sequences.\n",
    "\n",
    "This notebook provides a practical introduction to converting raw text into numerical formats suitable for deep learning, highlighting the transition from sparse one-hot representations to dense, semantically rich word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "# Define a list of example sentences for demonstration\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the vocabulary size\n",
    "# Define the size of the vocabulary. This determines the range of integer IDs for one-hot encoding.\n",
    "# A larger vocabulary size reduces collisions but may not always be necessary for small datasets.\n",
    "voc_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9984, 1599, 2422, 1287],\n",
       " [9984, 1599, 2422, 8590],\n",
       " [9984, 6765, 2422, 6548],\n",
       " [5044, 2929, 5027, 6590, 2913],\n",
       " [5044, 2929, 5027, 6590, 3885],\n",
       " [232, 9984, 9164, 2422, 8697],\n",
       " [6871, 4875, 8670, 6590]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### One Hot Representation\n",
    "# Apply one-hot encoding to each sentence\n",
    "# Each word in a sentence is converted into a unique integer ID within the `voc_size` range.\n",
    "one_hot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word Embedding Representation\n",
    "# Import necessary Keras layers and utilities for word embeddings\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences # Corrected import from .processing.sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np # Used for numerical operations, though not explicitly in this snippet's output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 9984 1599 2422 1287]\n",
      " [   0    0    0    0 9984 1599 2422 8590]\n",
      " [   0    0    0    0 9984 6765 2422 6548]\n",
      " [   0    0    0 5044 2929 5027 6590 2913]\n",
      " [   0    0    0 5044 2929 5027 6590 3885]\n",
      " [   0    0    0  232 9984 9164 2422 8697]\n",
      " [   0    0    0    0 6871 4875 8670 6590]]\n"
     ]
    }
   ],
   "source": [
    "# Define the desired length for all sequences after padding\n",
    "sent_length=8\n",
    "# Pad the one-hot encoded sequences to ensure uniform length\n",
    "# `padding='pre'` adds zeros to the beginning of shorter sequences.\n",
    "# `maxlen` specifies the target length.\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature representation\n",
    "# Define the dimensionality of the word embeddings (the size of the dense vector for each word)\n",
    "dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pro/python-learning/Machine Learning/4-simple-rnn-imdb/rnn-env/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Sequential Keras model\n",
    "model=Sequential()\n",
    "# Add an Embedding layer to the model\n",
    "# `voc_size`: The size of the vocabulary (maximum integer index + 1).\n",
    "# `dim`: The output dimension of the embedding (size of each word vector).\n",
    "# `input_length`: The length of input sequences (the `maxlen` used in padding).\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "# Compile the model. For an Embedding layer demonstration, the optimizer and loss\n",
    "# are not critical as we're primarily interested in the layer's output, not training.\n",
    "model.compile('adam','mse')  # Using Adam optimizer and Mean Squared Error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [-0.02918469, -0.00735456,  0.00391432, -0.01519922,\n",
       "         -0.04398937, -0.01802974,  0.00740063,  0.00415504,\n",
       "         -0.00951606, -0.01654055],\n",
       "        [ 0.03514184, -0.03198707, -0.03448869, -0.03153343,\n",
       "          0.03102025, -0.0177858 , -0.03443227, -0.0305138 ,\n",
       "          0.0246017 , -0.032864  ],\n",
       "        [ 0.02906818, -0.03571652, -0.03203621,  0.02484213,\n",
       "          0.00586796, -0.04693662, -0.03448329,  0.01983863,\n",
       "         -0.00617731, -0.02601473],\n",
       "        [-0.02935731,  0.01140916,  0.04591478,  0.00994821,\n",
       "          0.02463886,  0.02021671,  0.04962296, -0.02324928,\n",
       "          0.0493765 ,  0.02472606]],\n",
       "\n",
       "       [[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [-0.02918469, -0.00735456,  0.00391432, -0.01519922,\n",
       "         -0.04398937, -0.01802974,  0.00740063,  0.00415504,\n",
       "         -0.00951606, -0.01654055],\n",
       "        [ 0.03514184, -0.03198707, -0.03448869, -0.03153343,\n",
       "          0.03102025, -0.0177858 , -0.03443227, -0.0305138 ,\n",
       "          0.0246017 , -0.032864  ],\n",
       "        [ 0.02906818, -0.03571652, -0.03203621,  0.02484213,\n",
       "          0.00586796, -0.04693662, -0.03448329,  0.01983863,\n",
       "         -0.00617731, -0.02601473],\n",
       "        [ 0.01414502,  0.00728383, -0.04413962,  0.04708315,\n",
       "         -0.01911109,  0.03888996, -0.01443104, -0.03781671,\n",
       "          0.00271476, -0.01701859]],\n",
       "\n",
       "       [[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [-0.02918469, -0.00735456,  0.00391432, -0.01519922,\n",
       "         -0.04398937, -0.01802974,  0.00740063,  0.00415504,\n",
       "         -0.00951606, -0.01654055],\n",
       "        [-0.03291773,  0.04727813,  0.01983912, -0.0283026 ,\n",
       "         -0.0406299 ,  0.0279214 ,  0.01427466, -0.02500298,\n",
       "          0.0119329 ,  0.00641662],\n",
       "        [ 0.02906818, -0.03571652, -0.03203621,  0.02484213,\n",
       "          0.00586796, -0.04693662, -0.03448329,  0.01983863,\n",
       "         -0.00617731, -0.02601473],\n",
       "        [-0.02167455,  0.04519675, -0.02298274,  0.00896712,\n",
       "          0.00337492,  0.0284179 , -0.01989303, -0.02854747,\n",
       "          0.03813901,  0.03834668]],\n",
       "\n",
       "       [[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04523698,  0.03973236, -0.01720834,  0.02574886,\n",
       "         -0.00693867, -0.0305575 ,  0.02194091, -0.02220281,\n",
       "          0.02153516, -0.03683152],\n",
       "        [-0.04046195,  0.00485048,  0.03456872, -0.03075581,\n",
       "          0.02052584,  0.00257459, -0.02116987, -0.01148894,\n",
       "         -0.03563743, -0.02889245],\n",
       "        [-0.01957266, -0.00758915, -0.03496032, -0.02649205,\n",
       "          0.01268785, -0.01569651,  0.03502765, -0.00544006,\n",
       "         -0.00349575, -0.04786881],\n",
       "        [ 0.00733842, -0.03563062, -0.018757  , -0.04441105,\n",
       "          0.00381597,  0.03723998, -0.03802805, -0.0025013 ,\n",
       "          0.03321953, -0.00273781],\n",
       "        [-0.04737158, -0.00810834, -0.02043433,  0.04180907,\n",
       "          0.03993472,  0.03503698,  0.03742451,  0.03944153,\n",
       "          0.04091347,  0.02275589]],\n",
       "\n",
       "       [[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04523698,  0.03973236, -0.01720834,  0.02574886,\n",
       "         -0.00693867, -0.0305575 ,  0.02194091, -0.02220281,\n",
       "          0.02153516, -0.03683152],\n",
       "        [-0.04046195,  0.00485048,  0.03456872, -0.03075581,\n",
       "          0.02052584,  0.00257459, -0.02116987, -0.01148894,\n",
       "         -0.03563743, -0.02889245],\n",
       "        [-0.01957266, -0.00758915, -0.03496032, -0.02649205,\n",
       "          0.01268785, -0.01569651,  0.03502765, -0.00544006,\n",
       "         -0.00349575, -0.04786881],\n",
       "        [ 0.00733842, -0.03563062, -0.018757  , -0.04441105,\n",
       "          0.00381597,  0.03723998, -0.03802805, -0.0025013 ,\n",
       "          0.03321953, -0.00273781],\n",
       "        [ 0.00525533,  0.04027586,  0.02693193, -0.01355063,\n",
       "         -0.04681059, -0.00755756,  0.03267718,  0.00302451,\n",
       "          0.02433232, -0.04457901]],\n",
       "\n",
       "       [[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [-0.03761818,  0.0026795 , -0.01461645, -0.03763971,\n",
       "         -0.0331855 ,  0.03233615, -0.04224274,  0.04271099,\n",
       "         -0.04727942,  0.01533785],\n",
       "        [-0.02918469, -0.00735456,  0.00391432, -0.01519922,\n",
       "         -0.04398937, -0.01802974,  0.00740063,  0.00415504,\n",
       "         -0.00951606, -0.01654055],\n",
       "        [-0.02820728, -0.02282578,  0.032321  , -0.04965818,\n",
       "          0.03574118, -0.03101202, -0.00446746, -0.0159668 ,\n",
       "         -0.00686625,  0.01007464],\n",
       "        [ 0.02906818, -0.03571652, -0.03203621,  0.02484213,\n",
       "          0.00586796, -0.04693662, -0.03448329,  0.01983863,\n",
       "         -0.00617731, -0.02601473],\n",
       "        [-0.04503611,  0.01889792, -0.03436335, -0.03754349,\n",
       "         -0.02685362, -0.02443942,  0.02443259, -0.01939523,\n",
       "         -0.02296506, -0.02752832]],\n",
       "\n",
       "       [[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [-0.00228905,  0.0036517 ,  0.03304753,  0.03368105,\n",
       "         -0.04569585, -0.03988362,  0.01451614, -0.02799319,\n",
       "          0.02968064,  0.02392885],\n",
       "        [ 0.02374052,  0.01067281, -0.03013563,  0.00016127,\n",
       "         -0.01563423, -0.01176004, -0.01803283, -0.03185066,\n",
       "          0.04791374, -0.03807434],\n",
       "        [-0.03406482, -0.0115    , -0.00066115, -0.02602823,\n",
       "         -0.02189334,  0.01165424, -0.03431642, -0.02975758,\n",
       "         -0.03224266,  0.02115614],\n",
       "        [ 0.00733842, -0.03563062, -0.018757  , -0.04441105,\n",
       "          0.00381597,  0.03723998, -0.03802805, -0.0025013 ,\n",
       "          0.03321953, -0.00273781]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the model to predict (i.e., generate) the word embeddings for the padded documents\n",
    "# This will output a 3D array: (number_of_sentences, sequence_length, embedding_dimension)\n",
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   0,    0,    0,    0, 9984, 1599, 2422, 1287], dtype=int32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the one-hot encoded representation of the first sentence (before embedding)\n",
    "[embedded_docs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [ 0.04876981, -0.02584345,  0.01496186, -0.02252179,\n",
       "         -0.01341717,  0.0327312 , -0.03630286, -0.03725926,\n",
       "         -0.00585858, -0.01611942],\n",
       "        [-0.02918469, -0.00735456,  0.00391432, -0.01519922,\n",
       "         -0.04398937, -0.01802974,  0.00740063,  0.00415504,\n",
       "         -0.00951606, -0.01654055],\n",
       "        [ 0.03514184, -0.03198707, -0.03448869, -0.03153343,\n",
       "          0.03102025, -0.0177858 , -0.03443227, -0.0305138 ,\n",
       "          0.0246017 , -0.032864  ],\n",
       "        [ 0.02906818, -0.03571652, -0.03203621,  0.02484213,\n",
       "          0.00586796, -0.04693662, -0.03448329,  0.01983863,\n",
       "         -0.00617731, -0.02601473],\n",
       "        [-0.02935731,  0.01140916,  0.04591478,  0.00994821,\n",
       "          0.02463886,  0.02021671,  0.04962296, -0.02324928,\n",
       "          0.0493765 ,  0.02472606]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate and display the word embeddings for the first sentence\n",
    "# The output will be a 2D array: (sequence_length, embedding_dimension)\n",
    "dims = np.expand_dims(embedded_docs[0], axis=0)\n",
    "model.predict(dims)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
