{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Workflow Summary: Sentiment Analysis Example\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "- The video continues discussion on NLP topics like stemming, lemmatization, stopwords, using NLTK and Python.\n",
    "- Focus is on revising concepts through a **sentiment analysis** problem statement.\n",
    "\n",
    "---\n",
    "\n",
    "## Key NLP Concepts and Pipeline\n",
    "\n",
    "### 1. Text and Corpus\n",
    "- **Documents (d1, d2, d3, d4)**: Individual sentences or documents.\n",
    "- **Corpus**: Collection of documents or sentences (can be paragraphs).\n",
    "- **Vocabulary**: Set of unique words in the corpus.\n",
    "\n",
    "### 2. NLP Project Lifecycle for Sentiment Analysis\n",
    "- **Dataset**: Start with a dataset containing text data.\n",
    "- **Text Pre-processing**:\n",
    "  - **Part 1**:\n",
    "    - **Tokenization**: Split text into sentences or words.\n",
    "    - **Lowercasing**: Convert all text to lowercase to unify words like \"Though\" and \"though\".\n",
    "    - **Regular Expressions (Regex)**: Clean text by removing special characters or unwanted patterns.\n",
    "  - **Part 2**:\n",
    "    - **Stemming & Lemmatization**: Reduce words to base/root forms.\n",
    "    - **Stopwords Removal**: Remove common words that don’t add meaning.\n",
    "    \n",
    "  These steps clean and normalize the raw text.\n",
    "\n",
    "### 3. Text to Vectors (Numerical Representation)\n",
    "- After cleaning, text is converted into numerical vectors for ML models.\n",
    "- Techniques include:\n",
    "  - **One-Hot Encoding**: Simple, sparse vector; rarely used now for text.\n",
    "  - **Bag of Words (BoW)**: Counts occurrences of words.\n",
    "  - **TF-IDF (Term Frequency-Inverse Document Frequency)**: Weighs words by importance.\n",
    "  - **Word2Vec**: Generates dense word embeddings capturing semantic meaning.\n",
    "  - **Average Word2Vec**: Averages embeddings for document-level representation.\n",
    "- These techniques are foundational before deep learning methods like **transformers** and **BERT**.\n",
    "\n",
    "### 4. Model Training\n",
    "- Use the numerical vectors to train **machine learning algorithms** for classification tasks like sentiment analysis.\n",
    "- After training, evaluate performance by prediction accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Notes\n",
    "- **Gensim Library** is recommended for Word2Vec implementation; it supports pre-trained models and custom training.\n",
    "- Word embeddings (Word2Vec, etc.) use deep learning concepts to capture context.\n",
    "- Understanding vectorization techniques is critical before moving to advanced NLP methods.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of Workflow\n",
    "\n",
    "```plaintext\n",
    "Dataset\n",
    "   ↓\n",
    "Text Pre-processing\n",
    "   ├─ Tokenization\n",
    "   ├─ Lowercasing\n",
    "   ├─ Regex Cleaning\n",
    "   ├─ Stemming/Lemmatization\n",
    "   └─ Stopwords Removal\n",
    "   ↓\n",
    "Text to Vectors (One-Hot, BoW, TF-IDF, Word2Vec)\n",
    "   ↓\n",
    "Train ML Model (e.g. classification for sentiment analysis)\n",
    "   ↓\n",
    "Prediction & Evaluation\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
